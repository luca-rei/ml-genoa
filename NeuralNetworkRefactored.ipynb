{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetworkRefactored.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSgtC-5pEuxW"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from keras.optimizers import Nadam\n",
        "from keras import regularizers\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, TimeDistributed\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras import optimizers\n",
        "\n",
        "import joblib"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Iv0V5jFyrb"
      },
      "source": [
        "Upload data (someway, depending on your data).\n",
        "I'll assume they're encoded in a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S3h5XF5cHUm",
        "outputId": "7429156a-7add-44f1-ab40-4d7d286c8c8f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0liRxUnfZMt"
      },
      "source": [
        "fd = pd.read_pickle(\"/content/drive/My Drive/total.pickle\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjWLXf6qY068",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba915921-6705-4d31-c87c-faf8cb9b9ad4"
      },
      "source": [
        "print('samples x dimensions x nchannels x npoints ', fd.shape)\n",
        "print('dimensions x nchannels x npoints ',fd[0].shape)\n",
        "print('nchannels x npoints ', fd[0][0].shape)\n",
        "print('npoints', fd[0][0][0].shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "samples x dimensions x nchannels x npoints  (1000, 2, 4, 79)\n",
            "dimensions x nchannels x npoints  (2, 4, 79)\n",
            "nchannels x npoints  (4, 79)\n",
            "npoints (79,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5V6oCDKJVJm"
      },
      "source": [
        "Divide the data in training (validation) and test.\n",
        "In my dataset the data had already been shuffled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxKqY6CDFjA7"
      },
      "source": [
        "fd_train = np.stack((np.array([sample for sample in fd[:,0,0,:]])[:491], (fd[:491,1,0,:])), axis=-1)\n",
        "fd_test = np.stack((np.array([sample for sample in fd[:,0,0,:]])[491:], (fd[491:,1,0,:])), axis=-1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nrbwuerbb5r"
      },
      "source": [
        "x_amplitude = fd_train[:,:,0]\n",
        "x_phase=fd_train[:,:,1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "077kVpVAXe3X"
      },
      "source": [
        "Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6ZU5e8kb4-x"
      },
      "source": [
        "n_features=fd_train.shape[1]\n",
        "time_window=79"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUGUS2ilFjTZ"
      },
      "source": [
        "def baseline_model(dropout=0.4, bias1=1e-9, bias2=1e-9, ker1=1e-9, ker2=1e-9):\n",
        "  \n",
        "  model = Sequential()  \n",
        "  model.add(Dense(int(n_features/2), activation='tanh', input_shape=(time_window, 2), bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(Dense(int(n_features/4), activation='tanh', input_shape=(time_window, 2), bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))  \n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(Dense(int(n_features/2), activation='tanh', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
        "  model.add(Dense(int(n_features), activation='linear', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
        "  model.add(TimeDistributed(Dense(2)))\n",
        "  \n",
        "  model.compile(optimizer=Nadam(lr=5e-6), loss='mse', metrics=['mse'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGxBIGFQFjeC"
      },
      "source": [
        "mlp = KerasRegressor(build_fn=baseline_model, epochs=1, batch_size=n_features, verbose=0)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A69HAK6ueAaU"
      },
      "source": [
        "param_distr = dict(bias1 = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1], \n",
        "                   bias2 = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
        "                   ker2 = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1], \n",
        "                   ker1 = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
        "                   dropout = [1e-1, 2e-1, 3e-1, 4e-1, 5e-1])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGc0ftFbd56N"
      },
      "source": [
        "grid_search = GridSearchCV(estimator = mlp, param_grid=param_distr, cv=3)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzW1P1MsjIlu"
      },
      "source": [
        "grid_search.fit(fd_train, fd_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nweJaK_7jIvO"
      },
      "source": [
        "print(\"Best: %f using %s\" % (grid_search.best_score_, grid_search.best_params_))\n",
        "means  = grid_search.cv_results_['mean_test_score']\n",
        "stds   = grid_search.cv_results_['std_test_score']\n",
        "params = grid_search.cv_results_['params']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErRccpl1aE27"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ_adbrLaDF4"
      },
      "source": [
        "joblib.dump(grid_search.best_params_, 'best_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}