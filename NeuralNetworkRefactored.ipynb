{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rSgtC-5pEuxW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/loni5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/loni5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/loni5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/loni5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/loni5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/loni5/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from keras.optimizers import Nadam\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, TimeDistributed\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras import optimizers\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2Iv0V5jFyrb"
   },
   "source": [
    "Download data (someway, depending on your data).\n",
    "I'll assume they're encoded in a hdf5 (or Pandas) DataFrame.\n",
    "For the following I will assume you have the data, otherwise download a file like\n",
    "wget https://www.gw-openscience.org/archive/data/O2_16KHZ_R1/1163919360/L-L1_GWOSC_O2_16KHZ_R1-1164615680-4096.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'L-L1_GWOSC_O2_16KHZ_R1-1164615680-4096.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3S3h5XF5cHUm",
    "outputId": "7429156a-7add-44f1-ab40-4d7d286c8c8f"
   },
   "outputs": [],
   "source": [
    "fd = np.fromfile(filename, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5V6oCDKJVJm"
   },
   "source": [
    "Divide the data in training (validation) and test.\n",
    "In my dataset the data had already been shuffled. So first define a step, then stack n array of step elements each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fxKqY6CDFjA7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 1000\n",
    "fd = fd[:110*step]\n",
    "\n",
    "chunks = np.stack(np.split(fd,110))\n",
    "chunks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, over 164 chunks, I will use 150 as training and the remaining as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "th=100\n",
    "fd_train = chunks[:th]\n",
    "fd_test = chunks[th:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "077kVpVAXe3X"
   },
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "j6ZU5e8kb4-x"
   },
   "outputs": [],
   "source": [
    "n_features=fd_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hUGUS2ilFjTZ"
   },
   "outputs": [],
   "source": [
    "def baseline_model(dropout=0.4, bias1=1e-9, bias2=1e-9, ker1=1e-9, ker2=1e-9):\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_features, activation='relu', input_shape=(n_features,), bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(int(n_features/2), activation='relu', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(int(n_features/4), activation='relu', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(int(n_features/4), activation='sigmoid', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "    model.add(Dense(int(n_features/2), activation='sigmoid', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "    model.add(Dense(n_features, activation='sigmoid', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "\n",
    "    model.compile(optimizer=Nadam(lr=5e-6), loss='mse', metrics=['mse'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cGxBIGFQFjeC"
   },
   "outputs": [],
   "source": [
    "mlp = KerasRegressor(build_fn=baseline_model, epochs=1, batch_size=n_features, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A69HAK6ueAaU"
   },
   "source": [
    "some parameters to explore!\n",
    "param_distr = dict(bias1 = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1], \n",
    "                   bias2 = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "                   ker2 = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1], \n",
    "                   ker1 = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "                   dropout = [1e-1, 2e-1, 3e-1, 4e-1, 5e-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distr = dict(bias1 = [1e-9], \n",
    "                   bias2 = [1e-9],\n",
    "                   ker2 = [1e-9], \n",
    "                   ker1 = [1e-9],\n",
    "                   dropout = [1e-1, 2e-1, 3e-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qGc0ftFbd56N"
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = mlp, param_grid=param_distr, cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzW1P1MsjIlu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(fd_train, fd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nweJaK_7jIvO"
   },
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_search.best_score_, grid_search.best_params_))\n",
    "means  = grid_search.cv_results_['mean_test_score']\n",
    "stds   = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErRccpl1aE27"
   },
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJ_adbrLaDF4"
   },
   "outputs": [],
   "source": [
    "joblib.dump(grid_search.best_params_, 'best_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exercise: use the fd_test to see the performances!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NeuralNetworkRefactored.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
